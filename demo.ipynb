{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a20d42c2",
   "metadata": {},
   "source": [
    "## Sample Inference\n",
    "\n",
    "Inference run of our model on 20 sample images from the `PubTables-1M` test dataset located in the `./sample_pubtables1m` directory.\n",
    "The folder contains subfolders:\n",
    "- `images` with images used for the inference\n",
    "- `ocr` with ocr results from our custom internal ocr model\n",
    "- `ocr_gt` with ocr results provided in the PubTables-1M dataset\n",
    "- `test` with ground truth json files containing bounding boxes coordinates for tables, columns, rows, headers and extra_cells in the case of spanning cells\n",
    "\n",
    "The below code:\n",
    "- loads the model\n",
    "- runs the inference on 20 sample images\n",
    "- visualizes the output and saves it in the `./demo_results` directory\n",
    "    - images with `.table.jpg` suffix contain the prediction of our model\n",
    "    - other images contain the visualized ground truth and prediction for classes where some mistake was made\n",
    "- calculates average precision and average recall metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d5f087b-3d90-4f92-92b0-e83cf84f9989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_model 256\n",
      "is_sum_embeddings True\n",
      "use_content_emb True\n",
      "num_coords 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/efs/marco/gpt4hana/venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for jsons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 762.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 889.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for OCR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 1031.89it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 97.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current accuracy 0.9959655036832306\n",
      "For all (6) classes\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.901\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.946\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.903\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.962\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.865\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.883\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.463\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.804\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.917\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.983\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.888\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.900\n",
      "COCO metrics summary: AP: 0.901, AP50: 0.946, AR: 0.917\n",
      "best_score 0.9483608047574443\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import glob\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model_functions.transformer_tf_copy import TransformerEncoderTable\n",
    "from train_data_preparation.coco_tables_dataset import CocoValidDataset\n",
    "from train.table_extraction import collate_fn_pad, run_all_validations\n",
    "\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model_recognition = TransformerEncoderTable(num_clustering_heads=4, is_use_4_points=True,\n",
    "                                            is_use_image_patches=True, use_content_emb=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model_recognition.cuda(0)\n",
    "    # weights are in float16 precision\n",
    "    model_recognition.half()\n",
    "\n",
    "checkpoint_path_recognition = 'model_weights/table_recognition.pth'\n",
    "checkpoint_recognition = torch.load(checkpoint_path_recognition, map_location=device)\n",
    "model_recognition.load_state_dict(checkpoint_recognition, strict=False)\n",
    "model_recognition = model_recognition.float()\n",
    "model_recognition.eval()\n",
    "\n",
    "\n",
    "num_clustering_heads = 4\n",
    "class_map = {\n",
    "    'table': 0,\n",
    "    'table column': 1,\n",
    "    'column': 1,\n",
    "    'table row': 2,\n",
    "    'row': 2,\n",
    "    'table column header': 3,\n",
    "    'table header': 3,\n",
    "    'header': 3,\n",
    "    'no object': 6\n",
    "}\n",
    "\n",
    "# path to our validation datasets\n",
    "dataset_paths_validation = {\n",
    "    './sample_pubtables1m': 1,\n",
    "}\n",
    "eval_set = 'test'\n",
    "\n",
    "valid_dataset = CocoValidDataset(dataset_paths_validation,\n",
    "                                 eval_set,\n",
    "                                 class_map=class_map,\n",
    "                                 num_clustering_heads=num_clustering_heads,\n",
    "                                 ocr_labels_folder='ocr_gt',\n",
    "                                 is_use_4_points=True,\n",
    "                                 is_use_image_patches=True,\n",
    "                                 is_one_model='both',\n",
    "                                 use_cell_pointers=True,\n",
    "                                 is_augment_in_eval=False)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset,\n",
    "                          batch_size=1,\n",
    "                          shuffle=False,\n",
    "                          pin_memory=True,\n",
    "                          num_workers=8,\n",
    "                          drop_last=False,\n",
    "                          collate_fn=collate_fn_pad)\n",
    "\n",
    "output_dir = './demo_results'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "best_score = run_all_validations(model_recognition,\n",
    "                                 valid_loader,\n",
    "                                 output_dir,\n",
    "                                 is_use_4_points=True,\n",
    "                                 is_run_4_5_classes=False,\n",
    "                                 is_debug_plot=True,\n",
    "                                 is_augment_in_eval=False)\n",
    "\n",
    "print('best_score', best_score)\n",
    "print('END')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961c63f5",
   "metadata": {},
   "source": [
    "### Sample Model Training\n",
    "\n",
    "To run the sample training/finetuning with the same 20 images, please find the below code.\n",
    "Assumes that the previous cells in this jupyter notebook were already run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4920c50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters 15117192\n",
      "Looking for jsons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1110.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1260.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for OCR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 20887.97it/s]\n",
      "100%|██████████| 3/3 [00:17<00:00,  5.81s/it]\n"
     ]
    }
   ],
   "source": [
    "from train_data_preparation.tables_dataset import TrainTablesDataset\n",
    "from tqdm import trange, tqdm\n",
    "from train.table_extraction import compute_cost\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = model_recognition\n",
    "print('Number of model parameters', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "model.train()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda(0)\n",
    "\n",
    "# for the demo purposes, we use the same 20 sample images for finetuning\n",
    "dataset_paths = {\n",
    "    './sample_pubtables1m': 1,\n",
    "}\n",
    "\n",
    "train_dataset = TrainTablesDataset(dataset_paths,\n",
    "                                   class_map=class_map,\n",
    "                                   num_clustering_heads=num_clustering_heads,\n",
    "                                   ocr_labels_folder='ocr_gt',\n",
    "                                   is_use_4_points=True,\n",
    "                                   is_use_image_patches=True,\n",
    "                                   is_one_model='both',\n",
    "                                   use_cell_pointers=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=8,\n",
    "                          shuffle=True,\n",
    "                          pin_memory=True,\n",
    "                          num_workers=8,\n",
    "                          drop_last=True,\n",
    "                          collate_fn=collate_fn_pad)\n",
    "\n",
    "\n",
    "train_iterator = iter(train_loader)\n",
    "\n",
    "EPOCHS = 3\n",
    "STEPS_PER_EPOCH = 10\n",
    "best_score = 0.0\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "    model.train()\n",
    "    progress_bar = trange(STEPS_PER_EPOCH, leave=False, desc='Train')\n",
    "\n",
    "    for _ in progress_bar:\n",
    "        try:\n",
    "            word_boxes, contents_idx, _, adjacency_matrices, _, mask, _, img_patches, _, shadow_mask, _, header_mask = next(\n",
    "                train_iterator)\n",
    "        except StopIteration:\n",
    "            train_iterator = iter(train_loader)\n",
    "            word_boxes, contents_idx, _, adjacency_matrices, _, mask, _, img_patches, _, shadow_mask, _, header_mask = next(\n",
    "                train_iterator)\n",
    "\n",
    "        word_boxes = word_boxes.to(device)\n",
    "        img_patches = img_patches.to(device)\n",
    "        contents_idx = contents_idx.to(device)\n",
    "        mask = mask.to(device).float()\n",
    "        shadow_mask = shadow_mask.to(device).float()\n",
    "        header_mask = header_mask.to(device).float()\n",
    "        adjacency_matrices = adjacency_matrices.to(device)\n",
    "\n",
    "        preds_clustering = model(word_boxes, contents_idx, mask, img_patches)\n",
    "\n",
    "        cost = compute_cost(preds_clustering, adjacency_matrices, mask, shadow_mask, header_mask)\n",
    "\n",
    "        progress_bar.set_description(f'Train loss {cost:.6f}')\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
